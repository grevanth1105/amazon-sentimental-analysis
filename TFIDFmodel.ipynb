{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":800230,"sourceType":"datasetVersion","datasetId":1305},{"sourceId":10479620,"sourceType":"datasetVersion","datasetId":6489054}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import fireducks.pandas as pd\nimport os\n\n# Path to the extracted chunk files (from your Kaggle dataset structure)\nextracted_chunks_path = \"/kaggle/input/processed-chunks-1\"  # Adjust if the path differs\n\n# Combine all chunk files\nall_chunks = []\nfor file_name in sorted(os.listdir(extracted_chunks_path)):  # Ensure files are combined in order\n    if file_name.startswith(\"processed_chunk_\") and file_name.endswith(\".csv\"):\n        file_path = os.path.join(extracted_chunks_path, file_name)\n        print(f\"Loading {file_name}...\")\n        chunk = pd.read_csv(file_path)\n        all_chunks.append(chunk)\n\n# Concatenate all chunks into a single DataFrame\ncombined_data = pd.concat(all_chunks, ignore_index=True)\n\n# Display combined data info\nprint(\"Combined data shape:\", combined_data.shape)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-18T09:39:16.024033Z","iopub.execute_input":"2025-03-18T09:39:16.024393Z","iopub.status.idle":"2025-03-18T09:39:38.646333Z","shell.execute_reply.started":"2025-03-18T09:39:16.024363Z","shell.execute_reply":"2025-03-18T09:39:38.645281Z"}},"outputs":[{"name":"stdout","text":"Loading processed_chunk_0_50000.csv...\nLoading processed_chunk_1000000_1050000.csv...\nLoading processed_chunk_100000_150000.csv...\nLoading processed_chunk_1050000_1100000.csv...\nLoading processed_chunk_1100000_1150000.csv...\nLoading processed_chunk_1150000_1200000.csv...\nLoading processed_chunk_1200000_1250000.csv...\nLoading processed_chunk_1250000_1300000.csv...\nLoading processed_chunk_1300000_1350000.csv...\nLoading processed_chunk_1350000_1400000.csv...\nLoading processed_chunk_1400000_1450000.csv...\nLoading processed_chunk_1450000_1500000.csv...\nLoading processed_chunk_1500000_1550000.csv...\nLoading processed_chunk_150000_200000.csv...\nLoading processed_chunk_1550000_1600000.csv...\nLoading processed_chunk_1600000_1650000.csv...\nLoading processed_chunk_1650000_1700000.csv...\nLoading processed_chunk_1700000_1750000.csv...\nLoading processed_chunk_1750000_1800000.csv...\nLoading processed_chunk_1800000_1850000.csv...\nLoading processed_chunk_1850000_1900000.csv...\nLoading processed_chunk_1900000_1950000.csv...\nLoading processed_chunk_1950000_2000000.csv...\nLoading processed_chunk_2000000_2050000.csv...\nLoading processed_chunk_200000_250000.csv...\nLoading processed_chunk_2050000_2100000.csv...\nLoading processed_chunk_2100000_2150000.csv...\nLoading processed_chunk_2150000_2200000.csv...\nLoading processed_chunk_2200000_2250000.csv...\nLoading processed_chunk_2250000_2300000.csv...\nLoading processed_chunk_2300000_2350000.csv...\nLoading processed_chunk_2350000_2400000.csv...\nLoading processed_chunk_2400000_2450000.csv...\nLoading processed_chunk_2450000_2500000.csv...\nLoading processed_chunk_2500000_2550000.csv...\nLoading processed_chunk_250000_300000.csv...\nLoading processed_chunk_2550000_2600000.csv...\nLoading processed_chunk_2600000_2650000.csv...\nLoading processed_chunk_2650000_2700000.csv...\nLoading processed_chunk_2700000_2750000.csv...\nLoading processed_chunk_2750000_2800000.csv...\nLoading processed_chunk_2800000_2850000.csv...\nLoading processed_chunk_2850000_2900000.csv...\nLoading processed_chunk_2900000_2950000.csv...\nLoading processed_chunk_2950000_3000000.csv...\nLoading processed_chunk_3000000_3050000.csv...\nLoading processed_chunk_300000_350000.csv...\nLoading processed_chunk_3050000_3100000.csv...\nLoading processed_chunk_3100000_3150000.csv...\nLoading processed_chunk_3150000_3200000.csv...\nLoading processed_chunk_3200000_3250000.csv...\nLoading processed_chunk_3250000_3300000.csv...\nLoading processed_chunk_3300000_3350000.csv...\nLoading processed_chunk_3350000_3400000.csv...\nLoading processed_chunk_3400000_3450000.csv...\nLoading processed_chunk_3450000_3500000.csv...\nLoading processed_chunk_3500000_3550000.csv...\nLoading processed_chunk_350000_400000.csv...\nLoading processed_chunk_3550000_3600000.csv...\nLoading processed_chunk_400000_450000.csv...\nLoading processed_chunk_450000_500000.csv...\nLoading processed_chunk_500000_550000.csv...\nLoading processed_chunk_50000_100000.csv...\nLoading processed_chunk_550000_600000.csv...\nLoading processed_chunk_600000_650000.csv...\nLoading processed_chunk_650000_700000.csv...\nLoading processed_chunk_700000_750000.csv...\nLoading processed_chunk_750000_800000.csv...\nLoading processed_chunk_800000_850000.csv...\nLoading processed_chunk_850000_900000.csv...\nLoading processed_chunk_900000_950000.csv...\nLoading processed_chunk_950000_1000000.csv...\nCombined data shape: (3600000, 3)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Save the combined dataset as a CSV for future use\ncombined_data_path = \"/kaggle/working/combined_processed_data.csv\"\ncombined_data.to_csv(combined_data_path, index=False)\nprint(f\"Combined data saved at: {combined_data_path}\")\n# Load the saved combined dataset\ncombined_data = pd.read_csv(\"/kaggle/working/combined_processed_data.csv\")\n\n# Check the dataset structure\nprint(combined_data.info())\nprint(combined_data.head())\n# Check label distribution\nprint(combined_data['label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T09:40:42.139311Z","iopub.execute_input":"2025-03-18T09:40:42.139803Z","iopub.status.idle":"2025-03-18T09:40:59.954993Z","shell.execute_reply.started":"2025-03-18T09:40:42.139770Z","shell.execute_reply":"2025-03-18T09:40:59.953852Z"}},"outputs":[{"name":"stdout","text":"Combined data saved at: /kaggle/working/combined_processed_data.csv\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3600000 entries, 0 to 3599999\nData columns (total 3 columns):\n #   Column          Dtype \n---  ------          ----- \n 0   review          object\n 1   label           int64 \n 2   cleaned_review  object\ndtypes: int64(1), object(2)\nmemory usage: 82.4+ MB\nNone\n                                              review  label  \\\n0  Stuning even for the non-gamer: This sound tra...      2   \n1  The best soundtrack ever to anything.: I'm rea...      2   \n2  Amazing!: This soundtrack is my favorite music...      2   \n3  Excellent Soundtrack: I truly like this soundt...      2   \n4  Remember, Pull Your Jaw Off The Floor After He...      2   \n\n                                      cleaned_review  \n0  stun non gamer sound track beautiful paint sen...  \n1  good soundtrack read lot review say good game ...  \n2  amazing soundtrack favorite music time hand in...  \n3  excellent soundtrack truly like soundtrack enj...  \n4  remember pull Jaw Floor hear play game know di...  \nlabel\n2    1800000\n1    1800000\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data into train and test sets\nX = combined_data['cleaned_review']  # Features (cleaned reviews)\ny = combined_data['label']           # Labels (1 for neutral, 2 for positive)\n\n# Perform train-test split (80% training, 20% testing)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(f\"Training samples: {X_train.shape[0]}\")\nprint(f\"Testing samples: {X_test.shape[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T09:40:59.956619Z","iopub.execute_input":"2025-03-18T09:40:59.957004Z","iopub.status.idle":"2025-03-18T09:41:05.670933Z","shell.execute_reply.started":"2025-03-18T09:40:59.956966Z","shell.execute_reply":"2025-03-18T09:41:05.669527Z"}},"outputs":[{"name":"stdout","text":"Training samples: 2880000\nTesting samples: 720000\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# TF-IDF","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom joblib import Parallel, delayed\nimport pandas as pd\n\nX_train = X_train.fillna(\"\")\nX_test = X_test.fillna(\"\")\n\ndef preprocess_text(text):\n    return text.lower()\n\nprint(\"Starting parallel preprocessing...\")\nX_train_processed = Parallel(n_jobs=-1)(delayed(preprocess_text)(text) for text in X_train)\nX_test_processed = Parallel(n_jobs=-1)(delayed(preprocess_text)(text) for text in X_test)\nprint(\"Preprocessing complete!\")\n\ntfidf_vectorizer = TfidfVectorizer(\n    max_features=50000,\n    stop_words='english',\n    ngram_range=(1,2),\n    sublinear_tf=True,\n    max_df=0.95,\n    min_df=5\n)\n\nprint(\"Starting TF-IDF transformation...\")\nX_train_tfidf = tfidf_vectorizer.fit_transform(X_train_processed)\nX_test_tfidf = tfidf_vectorizer.transform(X_test_processed)\nprint(\"TF-IDF transformation complete!\")\n\nprint(f\"Train TF-IDF shape: {X_train_tfidf.shape}\")\nprint(f\"Test TF-IDF shape: {X_test_tfidf.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T12:58:30.615452Z","iopub.execute_input":"2025-03-17T12:58:30.616054Z","iopub.status.idle":"2025-03-17T13:09:33.449664Z","shell.execute_reply.started":"2025-03-17T12:58:30.616017Z","shell.execute_reply":"2025-03-17T13:09:33.448223Z"}},"outputs":[{"name":"stdout","text":"Starting parallel preprocessing...\nPreprocessing complete!\nStarting TF-IDF transformation...\nTF-IDF transformation complete!\nTrain TF-IDF shape: (2880000, 50000)\nTest TF-IDF shape: (720000, 50000)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# All in one","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport multiprocessing\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\nfrom sklearn.model_selection import KFold\nfrom scipy.stats import ttest_rel\nimport psutil\nfrom copy import deepcopy\nimport random\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T09:41:05.673075Z","iopub.execute_input":"2025-03-18T09:41:05.673640Z","iopub.status.idle":"2025-03-18T09:41:09.482563Z","shell.execute_reply.started":"2025-03-18T09:41:05.673606Z","shell.execute_reply":"2025-03-18T09:41:09.481142Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Function to check memory usage\ndef check_memory():\n    print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n\n# --- Load Preprocessed Data ---\nprocessed_dir = \"/kaggle/input/processed-chunks-1/\"\nprint(\"Loading preprocessed data from processed-chunks-1...\")\n\ncsv_files = sorted([f for f in os.listdir(processed_dir) if f.endswith('.csv')])\nprint(f\"Found {len(csv_files)} CSV files: {csv_files[:5]}...\")\n\ndataframes = []\nfor csv_file in tqdm(csv_files, desc=\"Loading CSV files\"):\n    file_path = os.path.join(processed_dir, csv_file)\n    df = pd.read_csv(file_path, usecols=['cleaned_review', 'label'])\n    dataframes.append(df)\n\ndata = pd.concat(dataframes, ignore_index=True)\nprint(f\"Total rows loaded: {len(data)}\")\n\n# Extract text and labels\ntext_column = 'cleaned_review'\nlabel_column = 'label'\nX = data[text_column].fillna(\"\")\ny = data[label_column].values\n\nprint(\"Label distribution before shuffling:\", np.bincount(y - 1))\n\n# Shuffle the dataset\nprint(\"Shuffling the dataset...\")\nnp.random.seed(42)\nshuffle_indices = np.random.permutation(len(data))\nX = X[shuffle_indices]\ny = y[shuffle_indices]\nprint(\"Label distribution after shuffling:\", np.bincount(y - 1))\n\n# Split into train (2.88M) and test (720K)\nX_train_processed = X[:2880000].tolist()\nX_test_processed = X[2880000:2880000 + 720000].tolist()\ny_train = y[:2880000]\ny_test = y[2880000:2880000 + 720000]\n\ny_train_adjusted = y_train - 1\ny_test_adjusted = y_test - 1\n\n# Initialize TF-IDF Vectorizer with fewer features\nprint(\"Initializing TF-IDF Vectorizer...\")\ntfidf_vectorizer = TfidfVectorizer(\n    max_features=2000,  # Reduced from 5000\n    min_df=5,\n    max_df=0.95,\n    ngram_range=(1, 2),\n    sublinear_tf=True\n)\n\nprint(\"Transforming text to TF-IDF features...\")\nX_train_tfidf = tfidf_vectorizer.fit_transform(X_train_processed)\nX_test_tfidf = tfidf_vectorizer.transform(X_test_processed)\nprint(\"TF-IDF transformation complete!\")\nprint(f\"Train TF-IDF shape: {X_train_tfidf.shape}\")\nprint(f\"Test TF-IDF shape: {X_test_tfidf.shape}\")\n\n# --- Model Evaluation ---\nN_CORES = multiprocessing.cpu_count() - 1\n\nmodel_templates = {\n    'SVM': LinearSVC(C=1.0, max_iter=1000, dual=True, random_state=42),\n    'Logistic Regression': LogisticRegression(C=1.0, max_iter=1000, n_jobs=N_CORES, random_state=42),\n    'Gaussian NB': GaussianNB(),\n    'MLP Classifier': MLPClassifier(hidden_layer_sizes=(50,), max_iter=100, learning_rate_init=0.001, random_state=42),  # Simplified\n    'XGBoost': XGBClassifier(n_estimators=50, max_depth=3, learning_rate=0.1, n_jobs=N_CORES, use_label_encoder=False, eval_metric='logloss', random_state=42),  # Reduced complexity\n    'LightGBM': lgb.LGBMClassifier(n_estimators=50, max_depth=3, n_jobs=N_CORES, random_state=42, verbose=-1)  # Reduced complexity\n}\n\n# Step 1: Train and evaluate on test set\naccuracies = {}\nprint(\"Training and evaluating models on test set...\")\nfor name, model_template in model_templates.items():\n    model = deepcopy(model_template)\n    subset_idx = random.sample(range(X_train_tfidf.shape[0]), 20000)  # Reduced from 50k\n    X_train_subset = X_train_tfidf[subset_idx]\n    y_train_subset = y_train_adjusted[subset_idx]\n    \n    # Convert to dense only for training subset if needed\n    if name in ['Gaussian NB', 'MLP Classifier', 'XGBoost', 'LightGBM']:\n        X_train_subset = X_train_subset.toarray()\n        # For test, predict in batches to avoid full dense conversion\n        batch_size = 50000\n        y_pred = []\n        for i in range(0, X_test_tfidf.shape[0], batch_size):\n            X_test_batch = X_test_tfidf[i:i + batch_size].toarray()\n            y_pred.extend(model.fit(X_train_subset, y_train_subset).predict(X_test_batch))\n        y_pred = np.array(y_pred)\n    else:\n        model.fit(X_train_subset, y_train_subset)\n        y_pred = model.predict(X_test_tfidf)\n    \n    y_pred_adjusted = y_pred + 1\n    acc = accuracy_score(y_test, y_pred_adjusted)\n    accuracies[name] = acc\n    print(f\"{name} Accuracy: {acc:.4f}\")\ncheck_memory()\n\ntop_models = sorted(accuracies.items(), key=lambda x: x[1], reverse=True)[:2]\nprint(\"\\nTop 2 models by accuracy:\")\nfor name, acc in top_models:\n    print(f\"{name}: {acc:.4f}\")\n\n# Step 2: 5-Fold Cross-Validation\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nmetrics = ['accuracy', 'f1', 'roc_auc']\nresults = {name: {metric: [] for metric in metrics} for name in model_templates.keys()}\n\nprint(\"\\nPerforming 5-fold cross-validation...\")\nfor name, model_template in model_templates.items():\n    print(f\"Cross-validating {name}...\")\n    for train_idx, val_idx in kf.split(X_train_tfidf):\n        X_train_fold = X_train_tfidf[train_idx]\n        y_train_fold = y_train_adjusted[train_idx]\n        X_val_fold = X_train_tfidf[val_idx]\n        y_val_fold = y_train_adjusted[val_idx]\n        \n        subset_idx = random.sample(range(X_train_fold.shape[0]), 20000)  # Reduced from 200k\n        X_train_subset = X_train_fold[subset_idx]\n        y_train_subset = y_train_fold[subset_idx]\n        \n        if name in ['Gaussian NB', 'MLP Classifier', 'XGBoost', 'LightGBM']:\n            X_train_subset = X_train_subset.toarray()\n            X_val_fold_converted = X_val_fold[:20000].toarray()  # Limit validation size\n            y_val_fold_converted = y_val_fold[:20000]\n        else:\n            X_val_fold_converted = X_val_fold\n            y_val_fold_converted = y_val_fold\n        \n        model = deepcopy(model_template)\n        model.fit(X_train_subset, y_train_subset)\n        y_pred_fold = model.predict(X_val_fold_converted)\n        \n        y_pred_fold_adjusted = y_pred_fold + 1\n        y_val_fold_adjusted = y_val_fold_converted + 1\n        \n        acc = accuracy_score(y_val_fold_adjusted, y_pred_fold_adjusted)\n        f1 = f1_score(y_val_fold_adjusted, y_pred_fold_adjusted, average='weighted')\n        \n        if hasattr(model, \"predict_proba\"):\n            y_prob_fold = model.predict_proba(X_val_fold_converted)[:, 1]\n            auc = roc_auc_score(y_val_fold_converted, y_prob_fold)\n        else:\n            if name == 'SVM':\n                y_scores_fold = model.decision_function(X_val_fold_converted)\n                auc = roc_auc_score(y_val_fold_converted, y_scores_fold)\n            else:\n                auc = np.nan\n        \n        results[name]['accuracy'].append(acc)\n        results[name]['f1'].append(f1)\n        results[name]['roc_auc'].append(auc)\n\n# Display CV results\nprint(\"\\n### 1. Perform K-Fold Cross-Validation and Report Detailed Performance Metrics\")\nprint(\"| Model              | Accuracy (Mean ± SD) | F1-Score (Mean ± SD) | AUC-ROC (Mean ± SD) |\")\nprint(\"|--------------------|---------------------|---------------------|--------------------|\")\nfor name in model_templates.keys():\n    acc_mean, acc_std = np.mean(results[name]['accuracy']), np.std(results[name]['accuracy'])\n    f1_mean, f1_std = np.mean(results[name]['f1']), np.std(results[name]['f1'])\n    auc_mean, auc_std = np.mean(results[name]['roc_auc']), np.std(results[name]['roc_auc'])\n    auc_mean_str = f\"{auc_mean:.2f}\" if not np.isnan(auc_mean) else \"nan\"\n    auc_std_str = f\"{auc_std:.2f}\" if not np.isnan(auc_std) else \"nan\"\n    print(f\"| {name:<18} | {acc_mean:.2f} ± {acc_std:.2f}         | {f1_mean:.2f} ± {f1_std:.2f}         | {auc_mean_str} ± {auc_std_str}        |\")\n\n# Step 3: Statistical Significance Tests\ntop_model_1_name, top_model_2_name = top_models[0][0], top_models[1][0]\ntop_model_1_scores = results[top_model_1_name]['accuracy']\ntop_model_2_scores = results[top_model_2_name]['accuracy']\n\nprint(\"\\n### 2. Conduct Statistical Significance Tests and Present p-Values\")\nprint(f\"Table: Statistical Significance of {top_model_1_name} and {top_model_2_name} vs. Other Models (TF-IDF)\")\nprint(\"| Comparison                  | p-value (Accuracy) | Significant? |\")\nprint(\"|-----------------------------|-------------------|--------------|\")\nfor name in model_templates.keys():\n    if name != top_model_1_name:\n        other_scores = results[name]['accuracy']\n        t_stat, p_value = ttest_rel(top_model_1_scores, other_scores)\n        significant = \"Yes\" if p_value < 0.05 else \"No\"\n        print(f\"| {top_model_1_name} vs. {name:<15} | {p_value:.3f}             | {significant:<12} |\")\nfor name in model_templates.keys():\n    if name != top_model_2_name and name != top_model_1_name:\n        other_scores = results[name]['accuracy']\n        t_stat, p_value = ttest_rel(top_model_2_scores, other_scores)\n        significant = \"Yes\" if p_value < 0.05 else \"No\"\n        print(f\"| {top_model_2_name} vs. {name:<15} | {p_value:.3f}             | {significant:<12} |\")\ncheck_memory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T09:41:19.993450Z","iopub.execute_input":"2025-03-18T09:41:19.994184Z","iopub.status.idle":"2025-03-18T10:16:13.125647Z","shell.execute_reply.started":"2025-03-18T09:41:19.994147Z","shell.execute_reply":"2025-03-18T10:16:13.122893Z"}},"outputs":[{"name":"stdout","text":"Loading preprocessed data from processed-chunks-1...\nFound 72 CSV files: ['processed_chunk_0_50000.csv', 'processed_chunk_1000000_1050000.csv', 'processed_chunk_100000_150000.csv', 'processed_chunk_1050000_1100000.csv', 'processed_chunk_1100000_1150000.csv']...\n","output_type":"stream"},{"name":"stderr","text":"Loading CSV files: 100%|██████████| 72/72 [00:19<00:00,  3.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Total rows loaded: 3600000\nLabel distribution before shuffling: [1800000 1800000]\nShuffling the dataset...\nLabel distribution after shuffling: [1800000 1800000]\nInitializing TF-IDF Vectorizer...\nTransforming text to TF-IDF features...\nTF-IDF transformation complete!\nTrain TF-IDF shape: (2880000, 2000)\nTest TF-IDF shape: (720000, 2000)\nTraining and evaluating models on test set...\nSVM Accuracy: 0.8488\nLogistic Regression Accuracy: 0.8548\nGaussian NB Accuracy: 0.7924\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"MLP Classifier Accuracy: 0.8362\nXGBoost Accuracy: 0.7606\nLightGBM Accuracy: 0.7654\nMemory usage: 56.1%\n\nTop 2 models by accuracy:\nLogistic Regression: 0.8548\nSVM: 0.8488\n\nPerforming 5-fold cross-validation...\nCross-validating SVM...\nCross-validating Logistic Regression...\nCross-validating Gaussian NB...\nCross-validating MLP Classifier...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Cross-validating XGBoost...\nCross-validating LightGBM...\n\n### 1. Perform K-Fold Cross-Validation and Report Detailed Performance Metrics\n| Model              | Accuracy (Mean ± SD) | F1-Score (Mean ± SD) | AUC-ROC (Mean ± SD) |\n|--------------------|---------------------|---------------------|--------------------|\n| SVM                | 0.85 ± 0.00         | 0.85 ± 0.00         | 0.93 ± 0.00        |\n| Logistic Regression | 0.85 ± 0.00         | 0.85 ± 0.00         | 0.93 ± 0.00        |\n| Gaussian NB        | 0.79 ± 0.00         | 0.79 ± 0.00         | 0.84 ± 0.00        |\n| MLP Classifier     | 0.83 ± 0.00         | 0.83 ± 0.00         | 0.92 ± 0.00        |\n| XGBoost            | 0.77 ± 0.00         | 0.77 ± 0.00         | 0.85 ± 0.00        |\n| LightGBM           | 0.77 ± 0.00         | 0.77 ± 0.00         | 0.85 ± 0.00        |\n\n### 2. Conduct Statistical Significance Tests and Present p-Values\nTable: Statistical Significance of Logistic Regression and SVM vs. Other Models (TF-IDF)\n| Comparison                  | p-value (Accuracy) | Significant? |\n|-----------------------------|-------------------|--------------|\n| Logistic Regression vs. SVM             | 0.000             | Yes          |\n| Logistic Regression vs. Gaussian NB     | 0.000             | Yes          |\n| Logistic Regression vs. MLP Classifier  | 0.000             | Yes          |\n| Logistic Regression vs. XGBoost         | 0.000             | Yes          |\n| Logistic Regression vs. LightGBM        | 0.000             | Yes          |\n| SVM vs. Gaussian NB     | 0.000             | Yes          |\n| SVM vs. MLP Classifier  | 0.000             | Yes          |\n| SVM vs. XGBoost         | 0.000             | Yes          |\n| SVM vs. LightGBM        | 0.000             | Yes          |\nMemory usage: 59.7%\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\nfrom scipy.stats import ttest_rel\nfrom copy import deepcopy\nimport random\n\n# Assuming model_templates, X_train_tfidf, y_train_adjusted are defined earlier\n# Step 2: 5-Fold Cross-Validation\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nmetrics = ['accuracy', 'f1', 'roc_auc']\nresults = {name: {metric: [] for metric in metrics} for name in model_templates.keys()}\n\nprint(\"\\nPerforming 5-fold cross-validation...\")\nfor name, model_template in model_templates.items():\n    print(f\"Cross-validating {name}...\")\n    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_tfidf)):\n        X_train_fold = X_train_tfidf[train_idx]\n        y_train_fold = y_train_adjusted[train_idx]\n        X_val_fold = X_train_tfidf[val_idx]\n        y_val_fold = y_train_adjusted[val_idx]\n        \n        # Increase subsample size to 50,000 for better variability\n        subset_idx = random.sample(range(X_train_fold.shape[0]), min(50000, X_train_fold.shape[0]))\n        X_train_subset = X_train_fold[subset_idx]\n        y_train_subset = y_train_fold[subset_idx]\n        \n        # Convert to dense format for specific models\n        if name in ['Gaussian NB', 'MLP Classifier', 'XGBoost', 'LightGBM']:\n            X_train_subset = X_train_subset.toarray()\n            X_val_fold_converted = X_val_fold[:20000].toarray()  # Limit validation size\n            y_val_fold_converted = y_val_fold[:20000]\n        else:\n            X_val_fold_converted = X_val_fold\n            y_val_fold_converted = y_val_fold\n        \n        model = deepcopy(model_template)\n        model.fit(X_train_subset, y_train_subset)\n        y_pred_fold = model.predict(X_val_fold_converted)\n        \n        # Adjust predictions and true labels if necessary (based on your y_train_adjusted)\n        y_pred_fold_adjusted = y_pred_fold + 1\n        y_val_fold_adjusted = y_val_fold_converted + 1\n        \n        # Calculate metrics\n        acc = accuracy_score(y_val_fold_adjusted, y_pred_fold_adjusted)\n        f1 = f1_score(y_val_fold_adjusted, y_pred_fold_adjusted, average='weighted')\n        \n        if hasattr(model, \"predict_proba\"):\n            y_prob_fold = model.predict_proba(X_val_fold_converted)[:, 1]\n            auc = roc_auc_score(y_val_fold_converted, y_prob_fold)\n        else:\n            if name == 'SVM':\n                y_scores_fold = model.decision_function(X_val_fold_converted)\n                auc = roc_auc_score(y_val_fold_converted, y_scores_fold)\n            else:\n                auc = np.nan\n        \n        # Store results\n        results[name]['accuracy'].append(acc)\n        results[name]['f1'].append(f1)\n        results[name]['roc_auc'].append(auc)\n        \n        # Print per-fold metrics with high precision for debugging\n        print(f\"{name} Fold {fold+1}: Acc={acc:.6f}, F1={f1:.6f}, AUC={auc:.6f}\" if not np.isnan(auc) else f\"{name} Fold {fold+1}: Acc={acc:.6f}, F1={f1:.6f}, AUC=nan\")\n\n# Display CV results with higher precision\nprint(\"\\n### 1. Perform K-Fold Cross-Validation and Report Detailed Performance Metrics\")\nprint(\"| Model              | Accuracy (Mean ± SD) | F1-Score (Mean ± SD) | AUC-ROC (Mean ± SD) |\")\nprint(\"|--------------------|---------------------|---------------------|--------------------|\")\nfor name in model_templates.keys():\n    acc_mean = np.mean(results[name]['accuracy'])\n    acc_std = np.std(results[name]['accuracy'])\n    f1_mean = np.mean(results[name]['f1'])\n    f1_std = np.std(results[name]['f1'])\n    auc_mean = np.mean(results[name]['roc_auc'])\n    auc_std = np.std(results[name]['roc_auc'])\n    auc_mean_str = f\"{auc_mean:.4f}\" if not np.isnan(auc_mean) else \"nan\"\n    auc_std_str = f\"{auc_std:.4f}\" if not np.isnan(auc_std) else \"nan\"\n    print(f\"| {name:<18} | {acc_mean:.4f} ± {acc_std:.4f} | {f1_mean:.4f} ± {f1_std:.4f} | {auc_mean_str} ± {auc_std_str} |\")\n\n# Step 3: Statistical Significance Tests\ntop_model_1_name = 'Logistic Regression'  # Based on your test set accuracy\ntop_model_2_name = 'SVM'\ntop_model_1_scores = results[top_model_1_name]['accuracy']\ntop_model_2_scores = results[top_model_2_name]['accuracy']\n\nprint(\"\\n### 2. Conduct Statistical Significance Tests and Present p-Values\")\nprint(f\"Table: Statistical Significance of {top_model_1_name} and {top_model_2_name} vs. Other Models (TF-IDF)\")\nprint(\"| Comparison                  | p-value (Accuracy) | Significant? |\")\nprint(\"|-----------------------------|-------------------|--------------|\")\nfor name in model_templates.keys():\n    if name != top_model_1_name:\n        other_scores = results[name]['accuracy']\n        t_stat, p_value = ttest_rel(top_model_1_scores, other_scores)\n        significant = \"Yes\" if p_value < 0.05 else \"No\"\n        print(f\"| {top_model_1_name} vs. {name:<15} | {p_value:.4f}             | {significant:<12} |\")\nfor name in model_templates.keys():\n    if name != top_model_2_name and name != top_model_1_name:\n        other_scores = results[name]['accuracy']\n        t_stat, p_value = ttest_rel(top_model_2_scores, other_scores)\n        significant = \"Yes\" if p_value < 0.05 else \"No\"\n        print(f\"| {top_model_2_name} vs. {name:<15} | {p_value:.4f}             | {significant:<12} |\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T10:21:10.942149Z","iopub.execute_input":"2025-03-18T10:21:10.942877Z","iopub.status.idle":"2025-03-18T10:37:34.907267Z","shell.execute_reply.started":"2025-03-18T10:21:10.942824Z","shell.execute_reply":"2025-03-18T10:37:34.905095Z"}},"outputs":[{"name":"stdout","text":"\nPerforming 5-fold cross-validation...\nCross-validating SVM...\nSVM Fold 1: Acc=0.859099, F1=0.859097, AUC=0.935535\nSVM Fold 2: Acc=0.860887, F1=0.860884, AUC=0.936437\nSVM Fold 3: Acc=0.858646, F1=0.858635, AUC=0.935452\nSVM Fold 4: Acc=0.860271, F1=0.860258, AUC=0.935928\nSVM Fold 5: Acc=0.861210, F1=0.861208, AUC=0.936635\nCross-validating Logistic Regression...\nLogistic Regression Fold 1: Acc=0.861326, F1=0.861320, AUC=0.937094\nLogistic Regression Fold 2: Acc=0.862458, F1=0.862455, AUC=0.937667\nLogistic Regression Fold 3: Acc=0.861554, F1=0.861548, AUC=0.936933\nLogistic Regression Fold 4: Acc=0.862319, F1=0.862312, AUC=0.937287\nLogistic Regression Fold 5: Acc=0.861387, F1=0.861386, AUC=0.937180\nCross-validating Gaussian NB...\nGaussian NB Fold 1: Acc=0.801750, F1=0.801749, AUC=0.848637\nGaussian NB Fold 2: Acc=0.797750, F1=0.797737, AUC=0.842509\nGaussian NB Fold 3: Acc=0.796150, F1=0.796122, AUC=0.841242\nGaussian NB Fold 4: Acc=0.801650, F1=0.801635, AUC=0.845590\nGaussian NB Fold 5: Acc=0.803050, F1=0.803065, AUC=0.848978\nCross-validating MLP Classifier...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"MLP Classifier Fold 1: Acc=0.845250, F1=0.845212, AUC=0.923597\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"MLP Classifier Fold 2: Acc=0.845200, F1=0.845186, AUC=0.923630\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"MLP Classifier Fold 3: Acc=0.842500, F1=0.842496, AUC=0.923523\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"MLP Classifier Fold 4: Acc=0.840250, F1=0.840228, AUC=0.921781\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"MLP Classifier Fold 5: Acc=0.845700, F1=0.845684, AUC=0.924760\nCross-validating XGBoost...\nXGBoost Fold 1: Acc=0.767650, F1=0.767376, AUC=0.851892\nXGBoost Fold 2: Acc=0.770500, F1=0.770073, AUC=0.854145\nXGBoost Fold 3: Acc=0.765600, F1=0.765194, AUC=0.853005\nXGBoost Fold 4: Acc=0.774250, F1=0.773979, AUC=0.854459\nXGBoost Fold 5: Acc=0.767900, F1=0.767087, AUC=0.853275\nCross-validating LightGBM...\nLightGBM Fold 1: Acc=0.766800, F1=0.766320, AUC=0.854885\nLightGBM Fold 2: Acc=0.772500, F1=0.772204, AUC=0.856524\nLightGBM Fold 3: Acc=0.766800, F1=0.766521, AUC=0.854544\nLightGBM Fold 4: Acc=0.774450, F1=0.774092, AUC=0.856043\nLightGBM Fold 5: Acc=0.768750, F1=0.768198, AUC=0.856622\n\n### 1. Perform K-Fold Cross-Validation and Report Detailed Performance Metrics\n| Model              | Accuracy (Mean ± SD) | F1-Score (Mean ± SD) | AUC-ROC (Mean ± SD) |\n|--------------------|---------------------|---------------------|--------------------|\n| SVM                | 0.8600 ± 0.0010 | 0.8600 ± 0.0010 | 0.9360 ± 0.0005 |\n| Logistic Regression | 0.8618 ± 0.0005 | 0.8618 ± 0.0005 | 0.9372 ± 0.0002 |\n| Gaussian NB        | 0.8001 ± 0.0026 | 0.8001 ± 0.0027 | 0.8454 ± 0.0031 |\n| MLP Classifier     | 0.8438 ± 0.0021 | 0.8438 ± 0.0021 | 0.9235 ± 0.0010 |\n| XGBoost            | 0.7692 ± 0.0030 | 0.7687 ± 0.0030 | 0.8534 ± 0.0009 |\n| LightGBM           | 0.7699 ± 0.0031 | 0.7695 ± 0.0031 | 0.8557 ± 0.0009 |\n\n### 2. Conduct Statistical Significance Tests and Present p-Values\nTable: Statistical Significance of Logistic Regression and SVM vs. Other Models (TF-IDF)\n| Comparison                  | p-value (Accuracy) | Significant? |\n|-----------------------------|-------------------|--------------|\n| Logistic Regression vs. SVM             | 0.0173             | Yes          |\n| Logistic Regression vs. Gaussian NB     | 0.0000             | Yes          |\n| Logistic Regression vs. MLP Classifier  | 0.0001             | Yes          |\n| Logistic Regression vs. XGBoost         | 0.0000             | Yes          |\n| Logistic Regression vs. LightGBM        | 0.0000             | Yes          |\n| SVM vs. Gaussian NB     | 0.0000             | Yes          |\n| SVM vs. MLP Classifier  | 0.0001             | Yes          |\n| SVM vs. XGBoost         | 0.0000             | Yes          |\n| SVM vs. LightGBM        | 0.0000             | Yes          |\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# LightGBM","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report, accuracy_score\nimport psutil\nimport numpy as np\n\n# Function to check memory usage\ndef check_memory():\n    print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n\n# Ensure labels are 0-based\ny_train_adjusted = np.array(y_train) - 1\ny_test_adjusted = np.array(y_test) - 1\n\n# Define LightGBM hyperparameters with reduced iterations and depth\nparam_grid = {\n    'learning_rate': [0.01, 0.05],\n    'n_estimators': [50, 100],\n    'max_depth': [3, 5],\n    'num_leaves': [15, 31]\n}\n\n# Stratified K-Fold Cross-Validation (using 3 folds for efficiency)\nkf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n\n# Iterate over hyperparameters\nfor lr in param_grid['learning_rate']:\n    for iterations in param_grid['n_estimators']:\n        for depth in param_grid['max_depth']:\n            for num_leaves in param_grid['num_leaves']:\n                print(f\"Training LightGBM with learning_rate={lr}, iterations={iterations}, depth={depth}, num_leaves={num_leaves}...\")\n                \n                # Initialize the LightGBM model\n                lgbm_classifier = lgb.LGBMClassifier(\n                    learning_rate=lr,\n                    n_estimators=iterations,\n                    max_depth=depth,\n                    num_leaves=num_leaves,\n                    verbose=-1,\n                    n_jobs=-1  # Utilize all CPU cores\n                )\n                \n                # Train on a subset for efficiency\n                subset_size = min(10000, X_train_tfidf.shape[0])\n                lgbm_classifier.fit(X_train_tfidf[:subset_size], y_train_adjusted[:subset_size])\n                \n                # Make predictions\n                y_pred_lgbm = lgbm_classifier.predict(X_test_tfidf) + 1  # Adjust back to original label scale\n                \n                # Performance evaluation\n                print(f\"LightGBM Classification Report (learning_rate={lr}, iterations={iterations}, depth={depth}, num_leaves={num_leaves}):\")\n                print(classification_report(y_test, y_pred_lgbm))\n                print(f\"LightGBM Accuracy: {accuracy_score(y_test, y_pred_lgbm):.4f}\\n\")\n                \n                # Check memory usage\n                check_memory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T16:03:06.701473Z","iopub.execute_input":"2025-02-12T16:03:06.702040Z","iopub.status.idle":"2025-02-12T16:04:46.686929Z","shell.execute_reply.started":"2025-02-12T16:03:06.701992Z","shell.execute_reply":"2025-02-12T16:04:46.685472Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CatBoost","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\nimport psutil\n\n# Function to check memory usage\ndef check_memory():\n    print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n\n# Ensure labels are 0-based\ny_train_adjusted = np.array(y_train) - 1\ny_test_adjusted = np.array(y_test) - 1\n\n# Define hyperparameter grid for CatBoost\nparam_grid = {\n    'learning_rate': [0.01, 0.05],\n    'iterations': [50, 100],\n    'depth': [3, 5],\n    'l2_leaf_reg': [1, 3],\n    'border_count': [32, 50]\n}\n\n# Stratified K-Fold Cross-Validation (using 3 folds for efficiency)\nkf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n\n# Iterate over hyperparameters\nfor lr in param_grid['learning_rate']:\n    for iterations in param_grid['iterations']:\n        for depth in param_grid['depth']:\n            for l2_leaf_reg in param_grid['l2_leaf_reg']:\n                for border_count in param_grid['border_count']:\n                    print(f\"Training CatBoost with learning_rate={lr}, iterations={iterations}, depth={depth}, l2_leaf_reg={l2_leaf_reg}, border_count={border_count}...\")\n                    \n                    # Initialize the CatBoost model\n                    catboost_classifier = CatBoostClassifier(\n                        learning_rate=lr,\n                        iterations=iterations,\n                        depth=depth,\n                        l2_leaf_reg=l2_leaf_reg,\n                        border_count=border_count,\n                        verbose=0,\n                        random_state=42\n                    )\n                    \n                    # Train on a subset for efficiency\n                    subset_size = min(10000, X_train_tfidf.shape[0])\n                    catboost_classifier.fit(X_train_tfidf[:subset_size], y_train_adjusted[:subset_size])\n                    \n                    # Make predictions\n                    y_pred_catboost = catboost_classifier.predict(X_test_tfidf) + 1  # Adjust back to original label scale\n                    \n                    # Performance evaluation\n                    print(f\"CatBoost Classification Report (learning_rate={lr}, iterations={iterations}, depth={depth}, l2_leaf_reg={l2_leaf_reg}, border_count={border_count}):\")\n                    print(classification_report(y_test, y_pred_catboost))\n                    print(f\"CatBoost Accuracy: {accuracy_score(y_test, y_pred_catboost):.4f}\\n\")\n                    \n                    # Check memory usage\n                    check_memory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T16:40:58.914692Z","iopub.execute_input":"2025-02-12T16:40:58.915170Z","iopub.status.idle":"2025-02-12T16:47:23.987782Z","shell.execute_reply.started":"2025-02-12T16:40:58.915139Z","shell.execute_reply":"2025-02-12T16:47:23.986466Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report, accuracy_score\nimport psutil\nimport numpy as np\n\n# Function to check memory usage\ndef check_memory():\n    print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n\n# Ensure labels are 0-based\ny_train_adjusted = np.array(y_train) - 1\ny_test_adjusted = np.array(y_test) - 1\n\n# Define hyperparameter grid for RandomForest\nparam_grid = {\n    'n_estimators': [50, 100],\n    'max_depth': [3, 5],\n    'min_samples_split': [2, 5]\n}\n\n# Stratified K-Fold Cross-Validation (using 3 folds for efficiency)\nkf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n\n# Iterate over hyperparameters\nfor n_estimators in param_grid['n_estimators']:\n    for depth in param_grid['max_depth']:\n        for min_samples_split in param_grid['min_samples_split']:\n            print(f\"Training Random Forest with n_estimators={n_estimators}, depth={depth}, min_samples_split={min_samples_split}...\")\n            \n            # Initialize the RandomForest model\n            rf_classifier = RandomForestClassifier(\n                n_estimators=n_estimators,\n                max_depth=depth,\n                min_samples_split=min_samples_split,\n                n_jobs=-1,  # Utilize all CPU cores\n                random_state=42\n            )\n            \n            # Train on a subset for efficiency\n            subset_size = min(10000, X_train_tfidf.shape[0])\n            rf_classifier.fit(X_train_tfidf[:subset_size], y_train_adjusted[:subset_size])\n            \n            # Make predictions\n            y_pred_rf = rf_classifier.predict(X_test_tfidf) + 1  # Adjust back to original label scale\n            \n            # Performance evaluation\n            print(f\"Random Forest Classification Report (n_estimators={n_estimators}, depth={depth}, min_samples_split={min_samples_split}):\")\n            print(classification_report(y_test, y_pred_rf))\n            print(f\"Random Forest Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\\n\")\n            \n            # Check memory usage\n            check_memory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T16:06:10.838580Z","iopub.execute_input":"2025-02-12T16:06:10.839377Z","iopub.status.idle":"2025-02-12T16:07:11.528080Z","shell.execute_reply.started":"2025-02-12T16:06:10.839341Z","shell.execute_reply":"2025-02-12T16:07:11.526899Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# AdaBoost","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report, accuracy_score\nimport psutil\nimport numpy as np\n\n# Function to check memory usage\ndef check_memory():\n    print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n\n# Ensure labels are 0-based\ny_train_adjusted = np.array(y_train) - 1\ny_test_adjusted = np.array(y_test) - 1\n\n# Define hyperparameter grid for AdaBoost\nparam_grid = {\n    'n_estimators': [50, 100],\n    'learning_rate': [0.01, 0.1]\n}\n\n# Stratified K-Fold Cross-Validation (using 3 folds for efficiency)\nkf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n\n# Iterate over hyperparameters\nfor n_estimators in param_grid['n_estimators']:\n    for learning_rate in param_grid['learning_rate']:\n        print(f\"Training AdaBoost with n_estimators={n_estimators}, learning_rate={learning_rate}...\")\n        \n        # Initialize the AdaBoost model\n        adaboost_classifier = AdaBoostClassifier(\n            n_estimators=n_estimators,\n            learning_rate=learning_rate,\n            random_state=42\n        )\n        \n        # Train on a subset for efficiency\n        subset_size = min(10000, X_train_tfidf.shape[0])\n        adaboost_classifier.fit(X_train_tfidf[:subset_size], y_train_adjusted[:subset_size])\n        \n        # Make predictions\n        y_pred_adaboost = adaboost_classifier.predict(X_test_tfidf) + 1  # Adjust back to original label scale\n        \n        # Performance evaluation\n        print(f\"AdaBoost Classification Report (n_estimators={n_estimators}, learning_rate={learning_rate}):\")\n        print(classification_report(y_test, y_pred_adaboost))\n        print(f\"AdaBoost Accuracy: {accuracy_score(y_test, y_pred_adaboost):.4f}\\n\")\n        \n        # Check memory usage\n        check_memory()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T16:16:36.198238Z","iopub.execute_input":"2025-02-12T16:16:36.198814Z","iopub.status.idle":"2025-02-12T16:20:43.324576Z","shell.execute_reply.started":"2025-02-12T16:16:36.198775Z","shell.execute_reply":"2025-02-12T16:20:43.323403Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Naive Bayes and SVM","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import classification_report, accuracy_score\nimport numpy as np\nimport psutil\n\n# Function to check memory usage\ndef check_memory():\n    print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n\n# Ensure labels are 0-based\ny_train_adjusted = np.array(y_train) - 1\ny_test_adjusted = np.array(y_test) - 1\n\n# Naive Bayes hyperparameter tuning\nalpha_values = [0.1, 0.5, 1.0, 2.0]\nfor alpha in alpha_values:\n    print(f\"Training Naive Bayes with alpha={alpha}...\")\n    nb_classifier = MultinomialNB(alpha=alpha)\n    nb_classifier.fit(X_train_tfidf, y_train_adjusted)\n    \n    # Predict\n    y_pred_nb = nb_classifier.predict(X_test_tfidf) + 1  # Adjust back to original labels\n    \n    # Performance evaluation\n    print(f\"Naive Bayes Classification Report (alpha={alpha}):\")\n    print(classification_report(y_test, y_pred_nb))\n    print(f\"Naive Bayes Accuracy: {accuracy_score(y_test, y_pred_nb):.4f}\\n\")\n    check_memory()\n\n# SVM hyperparameter tuning\nc_values = [0.1, 0.5, 1.0, 2.0]\nfor c_value in c_values:\n    print(f\"Training SVM with C={c_value}...\")\n    svm_classifier = LinearSVC(C=c_value, max_iter=5000, random_state=42)\n    svm_classifier.fit(X_train_tfidf, y_train_adjusted)\n    \n    # Predict\n    y_pred_svm = svm_classifier.predict(X_test_tfidf) + 1  # Adjust back to original labels\n    \n    # Performance evaluation\n    print(f\"SVM Classification Report (C={c_value}):\")\n    print(classification_report(y_test, y_pred_svm))\n    print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}\\n\")\n    check_memory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T17:14:53.320996Z","iopub.execute_input":"2025-02-12T17:14:53.321787Z","iopub.status.idle":"2025-02-12T17:20:55.153570Z","shell.execute_reply.started":"2025-02-12T17:14:53.321738Z","shell.execute_reply":"2025-02-12T17:20:55.152396Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MLP Classifier","metadata":{}},{"cell_type":"code","source":"# from sklearn.neural_network import MLPClassifier\n# from sklearn.metrics import classification_report, accuracy_score\n# import numpy as np\n# import psutil\n\n# # Function to check memory usage\n# def check_memory():\n#     print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n\n# # Ensure labels are 0-based\n# y_train_adjusted = np.array(y_train) - 1\n# y_test_adjusted = np.array(y_test) - 1\n\n# # Define hyperparameter grid for MLP\n# hidden_layer_sizes_values = [(100,), (128, 64)]\n# activation_values = ['relu', 'tanh']\n# solver_values = ['adam', 'sgd']\n\n# # Iterate over hyperparameters\n# for hidden_layer_sizes in hidden_layer_sizes_values:\n#     for activation in activation_values:\n#         for solver in solver_values:\n#             print(f\"Training MLPClassifier with hidden_layer_sizes={hidden_layer_sizes}, activation={activation}, solver={solver}...\")\n\n#             # Set up the MLPClassifier model with the specified hyperparameters\n#             mlp_classifier = MLPClassifier(\n#                 hidden_layer_sizes=hidden_layer_sizes,\n#                 activation=activation,\n#                 solver=solver,\n#                 max_iter=300,\n#                 random_state=42\n#             )\n\n#             # Train the model\n#             mlp_classifier.fit(X_train_tfidf[:50000], y_train_adjusted[:50000])  # Use a larger subset\n#             y_pred_mlp = mlp_classifier.predict(X_test_tfidf) + 1  # Adjust back to original labels\n\n#             # Performance reporting\n#             print(f\"MLPClassifier Classification Report for hidden_layer_sizes={hidden_layer_sizes}, activation={activation}, solver={solver}:\")\n#             print(classification_report(y_test, y_pred_mlp))\n#             print(f\"MLPClassifier Accuracy: {accuracy_score(y_test, y_pred_mlp):.4f}\\n\")\n\n#             # Check memory usage after each iteration\n#             check_memory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T17:34:08.167881Z","iopub.execute_input":"2025-02-12T17:34:08.168264Z","iopub.status.idle":"2025-02-12T17:34:08.172905Z","shell.execute_reply.started":"2025-02-12T17:34:08.168231Z","shell.execute_reply":"2025-02-12T17:34:08.171870Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# XG Boost","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\nimport psutil\n\n# Function to check memory usage\ndef check_memory():\n    print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n\n# Ensure labels are 0-based\ny_train_adjusted = np.array(y_train) - 1\ny_test_adjusted = np.array(y_test) - 1\n\n# Define hyperparameter grid for XGBoost\nparam_grid = {\n    'learning_rate': [0.01, 0.05, 0.1],\n    'n_estimators': [100, 200],\n    'max_depth': [3, 5],\n    'min_child_weight': [1, 5],\n    'gamma': [0, 0.1]\n}\n\n# Stratified K-Fold Cross-Validation (using 3 folds for efficiency)\nkf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n\n# Iterate over hyperparameters\nfor lr in param_grid['learning_rate']:\n    for n_est in param_grid['n_estimators']:\n        for max_depth in param_grid['max_depth']:\n            for min_child_weight in param_grid['min_child_weight']:\n                for gamma in param_grid['gamma']:\n                    print(f\"Training XGBoost with learning_rate={lr}, n_estimators={n_est}, max_depth={max_depth}, min_child_weight={min_child_weight}, gamma={gamma}...\")\n                    \n                    # Initialize the XGBoost model\n                    xgb_classifier = XGBClassifier(\n                        learning_rate=lr,\n                        n_estimators=n_est,\n                        max_depth=max_depth,\n                        min_child_weight=min_child_weight,\n                        gamma=gamma,\n                        use_label_encoder=False,\n                        eval_metric='logloss',\n                        tree_method='hist',\n                        random_state=42\n                    )\n                    \n                    # Train on a subset for efficiency\n                    subset_size = min(10000, X_train_tfidf.shape[0])\n                    xgb_classifier.fit(X_train_tfidf[:subset_size], y_train_adjusted[:subset_size])\n                    \n                    # Make predictions\n                    y_pred_xgb = xgb_classifier.predict(X_test_tfidf) + 1  # Adjust back to original label scale\n                    \n                    # Performance evaluation\n                    print(f\"XGBoost Classification Report (learning_rate={lr}, n_estimators={n_est}, max_depth={max_depth}, min_child_weight={min_child_weight}, gamma={gamma}):\")\n                    print(classification_report(y_test, y_pred_xgb))\n                    print(f\"XGBoost Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}\\n\")\n                    \n                    # Check memory usage\n                    check_memory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T16:22:51.982550Z","iopub.execute_input":"2025-02-12T16:22:51.983058Z","iopub.status.idle":"2025-02-12T16:35:31.390625Z","shell.execute_reply.started":"2025-02-12T16:22:51.983023Z","shell.execute_reply":"2025-02-12T16:35:31.389145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}